# 🛡️Awesome LLM-Safety🛡️[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

<p align="center">
<a href=""> <img src="https://img.shields.io/github/stars/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub stars"></a>
<a href=""> <img src="https://img.shields.io/github/forks/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub forks"></a>
<a href=""> <img src="https://img.shields.io/github/issues/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub issues"></a>
<a href=""> <img src="https://img.shields.io/github/last-commit/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub Last commit"></a>
</p>
<div align="center">

English | [中文](README_cn.md)

</div>

## 🤗Introduction


**Welcome to our Awesome-llm-safety repository!** 🥰🥰🥰

**🧑‍💻 Our Mission**

We've curated a collection of the latest 😋, most comprehensive 😎, and most valuable 🤩 resources on large language model safety (llm-safety). But we don't stop there; included are also relevant talks, tutorials, conferences, news, and articles. Our repository is constantly updated to ensure you have the most current information at your fingertips.

> If a resource is relevant to multiple subcategories, we place it under each applicable section. For instance, the "Awesome-LLM-Safety" repository will be listed under each subcategory to which it pertains🤩!.

**✔️ Perfect for Majority**
- For beginners curious about llm-safety, our repository serves as a compass for grasping the big picture and diving into the details. Classic or influential papers retained in the README provide a beginner-friendly navigation through interesting directions in the field;
- For seasoned researchers, this repository is a tool to keep you informed and fill any gaps in your knowledge. Within each subtopic, we are diligently updating all the latest content and continuously backfilling with previous work. Our thorough compilation and careful selection are time-savers for you.

**🧭 How to Use this Guide**
- Quick Start: In the README, users can find a curated list of select information sorted by date, along with links to various consultations.
- In-Depth Exploration: If you have a special interest in a particular subtopic, delve into the "subtopic" folder for more. Each item, be it an article or piece of news, comes with a brief introduction, allowing researchers to swiftly zero in on relevant content.


**Let’s start LLM Safety tutorial!**

---

## 🚀Table of Contents

- [🛡️Awesome LLM-Safety🛡️](#️awesome-llm-safety️)
  - [🤗Introduction](#introduction)
  - [🚀Table of Contents](#table-of-contents)
  - [🔐Security Tutorial](#security-tutorial)
    - [📑Papers](#papers)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks)
    - [Other](#other)
  - [🔏Privacy Tutorial](#privacy-tutorial)
    - [📑Papers](#papers-1)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks-1)
    - [Other](#other-1)
  - [📰Truthfulness\&Misinformation Tutorial](#truthfulnessmisinformation-tutorial)
    - [📑Papers](#papers-2)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks-2)
    - [Other](#other-2)
  - [😈JailBreak \& Attacks Tutorial](#jailbreak--attacks-tutorial)
    - [📑Papers](#papers-3)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks-3)
    - [Other](#other-3)
  - [🛡️Defenses Tutorial](#️defenses-tutorial)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks-4)
    - [Other](#other-4)
  - [💯Datasets \& Benchmark Tutorial](#datasets--benchmark-tutorial)
    - [📑Papers](#papers-4)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks-5)
    - [📚Resource📚](#resource)
    - [Other](#other-5)
  - [🧑‍🎓Author](#author)



---
## 🔐Security Tutorial

### 📑Papers
|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|
|20.10|Facebook AI Research|arxiv|[Recipes for Safety in Open-domain Chatbots](https://arxiv.org/abs/2010.07079)|
|23.07|UC Berkeley|arxiv|[Jailbroken: How Does LLM Safety Training Fail?](https://arxiv.org/abs/2307.02483)|
|23.07|CMU|arxiv|[Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)|


### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|


### Other

👉[Latest&Comprehensive Security Paper](.//subtopic/Security.md)

---
## 🔏Privacy Tutorial


### 📑Papers
|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|



### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|


### Other

👉[Latest&Comprehensive Privacy Paper](.//subtopic/Privacy.md)

---
## 📰Truthfulness&Misinformation Tutorial


### 📑Papers
|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|
|21.09|University of Oxford|ACL2022|[TruthfulQA: Measuring How Models Mimic Human Falsehoods](https://arxiv.org/abs/2109.07958)|


### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|

### Other

👉[Latest&Comprehensive Truthfulness&Misinformation Paper](./subtopic/Truthfulness&Misinformation.md)

---
## 😈JailBreak & Attacks Tutorial

### 📑Papers
|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|
|22.11|AE Studio|NIPS2022(ML Safety Workshop)|[Ignore Previous Prompt: Attack Techniques For Language Models](https://arxiv.org/abs/2211.09527)|
|23.06|Google|arxiv|[Are aligned neural networks adversarially aligned?](https://arxiv.org/abs/2306.15447)|
|23.07|CMU|arxiv|[Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)|

### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|

### Other

👉[Latest&Comprehensive JailBreak & Attacks Paper](./subtopic/Jailbreaks&Attack.md)

---
## 🛡️Defenses Tutorial

|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|
|22.04|Anthropic|arxiv|[Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2204.05862)|



### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|

### Other

👉[Latest&Comprehensive Defenses Paper](./subtopic/Defenses.md)


--- 
## 💯Datasets & Benchmark Tutorial

### 📑Papers
|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|
|20.09|University of Washington|EMNLP2020(findings)|[RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models](https://arxiv.org/abs/2009.11462)|
|21.09|University of Oxford|ACL2022|[TruthfulQA: Measuring How Models Mimic Human Falsehoods](https://arxiv.org/abs/2109.07958)|
|22.03|MIT|ACL2022|[ToxiGen: A Large-Scale Machine-Generated datasets for Adversarial and Implicit Hate Speech Detection](https://arxiv.org/abs/2203.09509)|


### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|

### 📚Resource📚
- Toxicity - [RealToxicityPrompts datasets](https://toxicdegeneration.allenai.org/)
- Truthfulness - [TruthfulQA datasets](https://github.com/sylinrl/TruthfulQA)

### Other
👉[Latest&Comprehensive datasets & Benchmark Paper](./subtopic/Datasets&Benchmark.md)


---
## 🧑‍🎓Author


**🤗If you have any questions, please contact our authors!🤗**

✉️: [ydyjya](https://github.com/ydyjya) ➡️ zhouzhenhong@bupt.edu.cn

💬: **LLM Safety Discussion**

<div align="center">

<img src="./resource/ydyjya%20wechat.jpg" width="300"/>
<img src="./resource/wechat.png" width="300", height="408"/>

</div>


---

[![Star History Chart](https://api.star-history.com/svg?repos=ydyjya/Awesome-LLM-Safety&type=Date)](https://star-history.com/#ydyjya/Awesome-LLM-Safety&Date)

**[⬆ Back to ToC](#table-of-contents)**