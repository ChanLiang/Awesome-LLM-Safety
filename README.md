# 🛡️Awesome LLM-Safety🛡️[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

<p align="center">
<a href=""> <img src="https://img.shields.io/github/stars/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub stars"></a>
<a href=""> <img src="https://img.shields.io/github/forks/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub forks"></a>
<a href=""> <img src="https://img.shields.io/github/issues/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub issues"></a>
<a href=""> <img src="https://img.shields.io/github/last-commit/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub Last commit"></a>
</p>

## 🤗Introduction


🥰🥰🥰**Welcome to our awesome-llm-safety repository!** 🥰🥰🥰

In this repo, you can retrieve the latest😋, comprehensive😎, safety papers on large language models. In addition, we will also do our best to update Talks, Presentations, Tutorials, Workshops, news and Articles🤗.


If the paper touches on multiple subtopics under security, we will place it under each subtopic.

> Like Awesome-LLM-Safety will appear in Tutorials for each subtopic🤩!

**Let’s start LLM Safety tutorial!**

---

## 🚀Table of Contents

- [🛡️Awesome LLM-Safety🛡️](#️awesome-llm-safety️)
  - [🤗Introduction](#introduction)
  - [🚀Table of Contents](#table-of-contents)
  - [🔐Security Tutorial](#security-tutorial)
    - [📑Papers](#papers)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks)
    - [Other](#other)
  - [🔏Privacy Tutorial](#privacy-tutorial)
    - [📑Papers](#papers-1)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks-1)
    - [Other](#other-1)
  - [📰Truthfulness\&Misinformation Tutorial](#truthfulnessmisinformation-tutorial)
    - [📑Papers](#papers-2)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks-2)
    - [Other](#other-2)
  - [😈JailBreak \& Attacks Tutorial](#jailbreak--attacks-tutorial)
    - [📑Papers](#papers-3)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks-3)
    - [Other](#other-3)
  - [🛡️Defenses Tutorial](#️defenses-tutorial)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks-4)
    - [Other](#other-4)
  - [💯Datasets \& Benchmark Tutorial](#datasets--benchmark-tutorial)
    - [📑Papers](#papers-4)
    - [📖Tutorials, Articles, Presentations and Talks](#tutorials-articles-presentations-and-talks-5)
    - [📚Resource📚](#resource)
    - [Other](#other-5)
  - [🧑‍🎓Author](#author)



---
## 🔐Security Tutorial

### 📑Papers
|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|
|20.10|Facebook AI Research|arxiv|[Recipes for Safety in Open-domain Chatbots](https://arxiv.org/abs/2010.07079)|
|23.07|UC Berkeley|arxiv|[Jailbroken: How Does LLM Safety Training Fail?](https://arxiv.org/abs/2307.02483)|
|23.07|CMU|arxiv|[Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)|


### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|


### Other

👉[Latest&Comprehensive Security Paper](.//subtopic/Security.md)

---
## 🔏Privacy Tutorial


### 📑Papers
|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|



### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|


### Other

👉[Latest&Comprehensive Privacy Paper](.//subtopic/Privacy.md)

---
## 📰Truthfulness&Misinformation Tutorial


### 📑Papers
|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|
|21.09|University of Oxford|ACL2022|[TruthfulQA: Measuring How Models Mimic Human Falsehoods](https://arxiv.org/abs/2109.07958)|


### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|

### Other

👉[Latest&Comprehensive Truthfulness&Misinformation Paper](./subtopic/Truthfulness&Misinformation.md)

---
## 😈JailBreak & Attacks Tutorial

### 📑Papers
|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|
|22.11|AE Studio|NIPS2022(ML Safety Workshop)|[Ignore Previous Prompt: Attack Techniques For Language Models](https://arxiv.org/abs/2211.09527)|
|23.06|Google|arxiv|[Are aligned neural networks adversarially aligned?](https://arxiv.org/abs/2306.15447)|
|23.07|CMU|arxiv|[Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)|

### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|

### Other

👉[Latest&Comprehensive JailBreak & Attacks Paper](./subtopic/JailBreak&Attacks.md)

---
## 🛡️Defenses Tutorial

|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|
|22.04|Anthropic|arxiv|[Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2204.05862)|



### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|

### Other

👉[Latest&Comprehensive Defenses Paper](./subtopic/Defenses.md)


--- 
## 💯Datasets & Benchmark Tutorial

### 📑Papers
|Date|Institute|Publication|Paper|
|:-:|:-:|:-:|:-:|
|20.09|University of Washington|EMNLP2020(findings)|[RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models](https://arxiv.org/abs/2009.11462)|
|21.09|University of Oxford|ACL2022|[TruthfulQA: Measuring How Models Mimic Human Falsehoods](https://arxiv.org/abs/2109.07958)|
|22.03|MIT|ACL2022|[ToxiGen: A Large-Scale Machine-Generated datasets for Adversarial and Implicit Hate Speech Detection](https://arxiv.org/abs/2203.09509)|


### 📖Tutorials, Articles, Presentations and Talks

|Date|Type|Title|URL|
|:-:|:-:|:-:|:-:|
|23.10|Tutorials|Awesome-LLM-Safety|[link](https://github.com/ydyjya/Awesome-LLM-Safety)|

### 📚Resource📚
- Toxicity - [RealToxicityPrompts datasets](https://toxicdegeneration.allenai.org/)
- Truthfulness - [TruthfulQA datasets](https://github.com/sylinrl/TruthfulQA)

### Other
👉[Latest&Comprehensive datasets & Benchmark Paper](./subtopic/Datasets&Benchmark.md)


---
## 🧑‍🎓Author


**🤗If you have any questions, please contact our authors!🤗**

✉️: [ydyjya](https://github.com/ydyjya) ➡️ zhouzhenhong@bupt.edu.cn


[![Star History Chart](https://api.star-history.com/svg?repos=ydyjya/Awesome-LLM-Safety&type=Date)](https://star-history.com/#ydyjya/Awesome-LLM-Safety&Date)

**[⬆ Back to ToC](#table-of-contents)**