# LLM-SecurityPapers


## Table of Contents

- [LLM-SecurityPapers](#llm-securitypapers)
  - [Table of Contents](#table-of-contents)
  - [Introduction](#introduction)
  - [Security](#security)
      - [📑Papers📑](#papers)
      - [💻Presentations \& Talks💻](#presentations--talks)
      - [📖Tutorials \& Workshops📖](#tutorials--workshops)
      - [📰News \& Articles📰](#news--articles)
  - [Privacy](#privacy)
      - [📑Papers📑](#papers-1)
      - [💻Presentations \& Talks💻](#presentations--talks-1)
      - [📖Tutorials \& Workshops📖](#tutorials--workshops-1)
      - [📰News \& Articles📰](#news--articles-1)
  - [Misinformation \& Hallucination](#misinformation--hallucination)
      - [📑Papers📑](#papers-2)
      - [💻Presentations \& Talks💻](#presentations--talks-2)
      - [📖Tutorials \& Workshops📖](#tutorials--workshops-2)
      - [📰News \& Articles📰](#news--articles-2)
  - [Adversarial Attacks](#adversarial-attacks)
      - [📑Papers📑](#papers-3)
      - [💻Presentations \& Talks💻](#presentations--talks-3)
      - [📖Tutorials \& Workshops📖](#tutorials--workshops-3)
      - [📰News \& Articles📰](#news--articles-3)
  - [Defenses](#defenses)
      - [📑Papers📑](#papers-4)
      - [💻Presentations \& Talks💻](#presentations--talks-4)
      - [📖Tutorials \& Workshops📖](#tutorials--workshops-4)
      - [📰News \& Articles📰](#news--articles-4)
  - [Dataset \& Benchmark](#dataset--benchmark)
      - [📑Papers📑](#papers-5)
      - [📚Resource📚](#resource)
  - [Author](#author)

## Introduction


🥰🥰🥰**Welcome to our awesome-llm-safety-paper-list repository!** 🥰🥰🥰

In this repo, you can retrieve the latest😋, comprehensive😎, safety papers on large language models. In addition, we will also do our best to update Talks, Presentations, Tutorials, Workshops, news and Articles🤗.

😊In order to allow everyone to search for the paper they need more quickly, we will mark the paper with several keywords. 

For example, 
- 23.10(**Timestamp**) - GitHub(**Publication Information**) - [awesome-LLM-safety-paper-list](https://github.com/ydyjya/awesome-LLM-safety-paper-list)
  - **Repo(keyword1)**&**Tutorials(keyword2)**

If the paper touches on multiple subtopics under security, we will place it under each subtopic.

> Like awesome-LLM-safety-paper-list will appear in Tutorials for each subtopic🤩!

**Let’s start learning LLM Safety!**

---
## Security

#### 📑Papers📑

- 20.10 - arxiv - [Recipes for Safety in Open-domain Chatbots](https://arxiv.org/abs/2010.07079)
  - **Toxic Behavior**&**Open-domain**
- 23.07 - arxiv - [Jailbroken: How Does LLM Safety Training Fail?](https://arxiv.org/abs/2307.02483)
  - **Jailbreak**&**Competing Objectives**&**Mismatched Generalization**
- 23.07 - arxiv  - [Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)
  - **Jailbreak**&**Transferable Attack**&**Adversarial Attack**

#### 💻Presentations & Talks💻


#### 📖Tutorials & Workshops📖

- 23.10 - GitHub - [awesome-LLM-safety-paper-list](https://github.com/ydyjya/awesome-LLM-safety-paper-list)
  - **Repo**&**Tutorials**

#### 📰News & Articles📰


---
## Privacy

#### 📑Papers📑
- 23.10 - arxiv - [Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory](https://arxiv.org/abs/2310.17884)
  - **Benchmark**&**Contextual Privacy**&**Chain-of-thought**

#### 💻Presentations & Talks💻


#### 📖Tutorials & Workshops📖

- 23.10 - GitHub - [awesome-LLM-safety-paper-list](https://github.com/ydyjya/awesome-LLM-safety-paper-list)
  - **Repo**&**Tutorials**

#### 📰News & Articles📰


---
## Truthfulness

#### 📑Papers📑
- 21.09 - ACL2022 - [TruthfulQA: Measuring How Models Mimic Human Falsehoods](https://arxiv.org/abs/2109.07958)
  - **Benchmark**&**Truthfulness**
- 23.10 - arxiv - [Lost in Translation -- Multilingual Misinformation and its Evolution](https://arxiv.org/abs/2310.18089)
  - **Misinformation**&**Multilingual**
- 23.10 - arxiv - [Personas as a Way to Model Truthfulness in Language Models](https://arxiv.org/abs/2310.18168)
  - **Truthfulness**&**Truthful Persona**

#### 💻Presentations & Talks💻


#### 📖Tutorials & Workshops📖

- 23.10 - GitHub - [awesome-LLM-safety-paper-list](https://github.com/ydyjya/awesome-LLM-safety-paper-list)
  - **Repo**&**Tutorials**

#### 📰News & Articles📰


---
## Attacks

#### 📑Papers📑

- 22.11 - NIPS2022(ML Safety Workshop) - [Ignore Previous Prompt: Attack Techniques For Language Models](https://arxiv.org/abs/2211.09527)
  - **Prompt Injection**&**Misaligned**
- 23.02 - arxiv - [Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection](https://arxiv.org/abs/2302.12173)
  - **Adversarial Prompting**&**Indirect Prompt Injection**&**LLM-Integrated Applications**
- 23.06 - arxiv - [Are aligned neural networks adversarially aligned?](https://arxiv.org/abs/2306.15447)
  - **Multimodal**&**Jailbreak**
- 23.07 - arxiv - [Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)
  - **Jailbreak**&**Transferable Attack**&**Adversarial Attack**

#### 💻Presentations & Talks💻


#### 📖Tutorials & Workshops📖

- 23.10 - GitHub - [awesome-LLM-safety-paper-list](https://github.com/ydyjya/awesome-LLM-safety-paper-list)
  - **Repo**&**Tutorials**

#### 📰News & Articles📰


---
## Defenses

#### 📑Papers📑

- 22.04 - arxiv - [Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2204.05862)
  - **Helpful**&**Harmless Principle**
- 23.09 - arxiv - [Certifying LLM Safety against Adversarial Prompting](https://arxiv.org/abs/2309.02705)
  - **Safety Filter**&**Adversarial Prompts**
- 23.10 - arxiv - [SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks](https://arxiv.org/abs/2310.03684)
  - **Jailbreak**&**Adversarial Attack**&**Perturbation**

#### 💻Presentations & Talks💻


#### 📖Tutorials & Workshops📖

- 23.10 - GitHub - [awesome-LLM-safety-paper-list](https://github.com/ydyjya/awesome-LLM-safety-paper-list)
  - **Repo**&**Tutorials**

#### 📰News & Articles📰

---
## Dataset & Benchmark

#### 📑Papers📑
- 20.09 - EMNLP2020(findings) - [RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models](https://arxiv.org/abs/2009.11462)
  - **Toxicity**
- 21.09 - ACL2022 - [TruthfulQA: Measuring How Models Mimic Human Falsehoods](https://arxiv.org/abs/2109.07958)
  - **Truthfulness**
- 22.03 - ACL2022 - [ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection](https://arxiv.org/abs/2203.09509)
  - **Toxicity**
#### 📚Resource📚
- 20.09 - URL - [RealToxicityPrompts Dataset](https://toxicdegeneration.allenai.org/)
  - **Toxicity**
- 21.09 - URL - [TruthfulQA Dataset](https://github.com/sylinrl/TruthfulQA)
  - **Truthfulness**

---
## Author


**🤗If you have any questions, please contact our authors!🤗**

✉️: [ydyjya](https://github.com/ydyjya) ➡️ zhouzhenhong@bupt.edu.cn
