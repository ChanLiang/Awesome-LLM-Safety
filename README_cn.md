# 🛡️Awesome LLM-Safety🛡️[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

<p align="center">
<a href=""> <img src="https://img.shields.io/github/stars/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub stars"></a>
<a href=""> <img src="https://img.shields.io/github/forks/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub forks"></a>
<a href=""> <img src="https://img.shields.io/github/issues/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub issues"></a>
<a href=""> <img src="https://img.shields.io/github/last-commit/ydyjya/Awesome-LLM-Safety?style=flat-square&logo=github" alt="GitHub Last commit"></a>
</p>

<div align="center">

[English](README.md) | 中文

</div>

## 🤗介绍

这是一个有关llm-safety的宝藏仓库！🥰🥰🥰

**🧑‍💻我们的工作：**
我们精心挑选并罗列了有关大模型安全方面（llm-safety）最新😋、最全面😎、最有价值🤩的论文。不仅如此，我们还附上了有关的演讲、教程、会议、新闻以及文章。这个仓库将实时更新，保证第一手资料。

>如果一份资料同时属于多个子分类，那么它将被同时放在这些子分类下。比如 “ Awesome-LLM-Safety”这个仓库将被放在每个子分类下。

**✔️适合多数人：**
- 对于希望了解llm-safety的初学者，这个仓库可以作为你把握框架，并了解细节的导航。我们在README中保留了比较经典或有影响力的论文，对初学者寻找感兴趣的方向十分友好；
- 对于资深的研究者，这个仓库可以作为你了解实况信息、查漏补缺的工具，在subtopic中，我们正在努力更新这个subtopic下的所有最新内容，并且将会不断补完之前的内容。全面的资料搜集以及用心地筛选可以帮助你节省时间；

**🧭使用指南：**
- 简略版：在README中，使用者可以找到按时间排列好的精选资讯，以及各种咨询的链接
- 详细版：如果对某一子话题特别感兴趣，可以点开“subtopic”文件夹，进一步了解。里面有对每篇文章或者资讯的简略介绍，可以帮助研究者快速锁定内容。

<center>🥰🥰🥰让我们开始llm-safety学习之旅吧🥰🥰🥰</center>

---

## 🚀目录

- [🛡️Awesome LLM-Safety🛡️](#️awesome-llm-safety️)
  - [🤗介绍](#介绍)
  - [🚀目录](#目录)
  - [🔐模型安全（Security Tutorial）](#模型安全security-tutorial)
    - [📑论文](#论文)
    - [📖教程, 文章, 演示, 演讲](#教程-文章-演示-演讲)
    - [其他](#其他)
  - [🔏隐私保护（Privacy Tutorial）](#隐私保护privacy-tutorial)
    - [📑论文](#论文-1)
    - [📖教程, 文章, 演示, 演讲](#教程-文章-演示-演讲-1)
    - [其他](#其他-1)
  - [📰事实性\&错误信息（Truthfulness\&Misinformation Tutorial）](#事实性错误信息truthfulnessmisinformation-tutorial)
    - [📑论文](#论文-2)
    - [📖教程, 文章, 演示, 演讲](#教程-文章-演示-演讲-2)
    - [其他](#其他-2)
  - [😈越狱\&攻击（JailBreak \& Attacks Tutorial）](#越狱攻击jailbreak--attacks-tutorial)
    - [📑论文](#论文-3)
    - [📖教程, 文章, 演示, 演讲](#教程-文章-演示-演讲-3)
    - [其他](#其他-3)
  - [🛡️防御措施（Defenses Tutorial）](#️防御措施defenses-tutorial)
    - [📖教程, 文章, 演示, 演讲](#教程-文章-演示-演讲-4)
    - [其他](#其他-4)
  - [💯数据集 \& 评测基准（Datasets \& Benchmark Tutorial）](#数据集--评测基准datasets--benchmark-tutorial)
    - [📑论文](#论文-4)
    - [📖教程, 文章, 演示, 演讲](#教程-文章-演示-演讲-5)
    - [📚资源📚](#资源)
    - [其他](#其他-5)
  - [🧑‍🎓作者信息](#作者信息)

---
## 🔐模型安全（Security Tutorial）

### 📑论文
|日期|机构|出版信息|论文&链接|
|:-:|:-:|:-:|:-:|
|20.10|Facebook AI Research|arxiv|[Recipes for Safety in Open-domain Chatbots](https://arxiv.org/abs/2010.07079)|
|23.07|UC Berkeley|arxiv|[Jailbroken: How Does LLM Safety Training Fail?](https://arxiv.org/abs/2307.02483)|
|23.07|CMU|arxiv|[Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)|


### 📖教程, 文章, 演示, 演讲

|日期|分类|标题|链接地址|
|:-:|:-:|:-:|:-:|
|23.10|教程|Awesome-LLM-Safety|[链接](https://github.com/ydyjya/Awesome-LLM-Safety)|


### 其他

👉[Latest&Comprehensive Security Paper](.//subtopic/Security.md)

---
## 🔏隐私保护（Privacy Tutorial）


### 📑论文
|日期|机构|出版信息|论文&链接|
|:-:|:-:|:-:|:-:|



### 📖教程, 文章, 演示, 演讲

|日期|分类|标题|链接地址|
|:-:|:-:|:-:|:-:|
|23.10|教程|Awesome-LLM-Safety|[链接](https://github.com/ydyjya/Awesome-LLM-Safety)|


### 其他

👉[Latest&Comprehensive Privacy Paper](.//subtopic/Privacy.md)

---
## 📰事实性&错误信息（Truthfulness&Misinformation Tutorial）


### 📑论文
|日期|机构|出版信息|论文&链接|
|:-:|:-:|:-:|:-:|
|21.09|University of Oxford|ACL2022|[TruthfulQA: Measuring How Models Mimic Human Falsehoods](https://arxiv.org/abs/2109.07958)|


### 📖教程, 文章, 演示, 演讲

|日期|分类|标题|链接地址|
|:-:|:-:|:-:|:-:|
|23.10|教程|Awesome-LLM-Safety|[链接](https://github.com/ydyjya/Awesome-LLM-Safety)|

### 其他

👉[Latest&Comprehensive Truthfulness&Misinformation Paper](./subtopic/Truthfulness&Misinformation.md)

---
## 😈越狱&攻击（JailBreak & Attacks Tutorial）

### 📑论文
|日期|机构|出版信息|论文&链接|
|:-:|:-:|:-:|:-:|
|22.11|AE Studio|NIPS2022(ML Safety Workshop)|[Ignore Previous Prompt: Attack Techniques For Language Models](https://arxiv.org/abs/2211.09527)|
|23.06|Google|arxiv|[Are aligned neural networks adversarially aligned?](https://arxiv.org/abs/2306.15447)|
|23.07|CMU|arxiv|[Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)|

### 📖教程, 文章, 演示, 演讲

|日期|分类|标题|链接地址|
|:-:|:-:|:-:|:-:|
|23.10|教程|Awesome-LLM-Safety|[链接](https://github.com/ydyjya/Awesome-LLM-Safety)|

### 其他

👉[Latest&Comprehensive JailBreak & Attacks Paper](./subtopic/Jailbreaks&Attack.md)

---
## 🛡️防御措施（Defenses Tutorial）

|日期|机构|出版信息|论文&链接|
|:-:|:-:|:-:|:-:|
|22.04|Anthropic|arxiv|[Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2204.05862)|



### 📖教程, 文章, 演示, 演讲

|日期|分类|标题|链接地址|
|:-:|:-:|:-:|:-:|
|23.10|教程|Awesome-LLM-Safety|[链接](https://github.com/ydyjya/Awesome-LLM-Safety)|

### 其他

👉[Latest&Comprehensive Defenses Paper](./subtopic/Defenses.md)


--- 
## 💯数据集 & 评测基准（Datasets & Benchmark Tutorial）

### 📑论文
|日期|机构|出版信息|论文&链接|
|:-:|:-:|:-:|:-:|
|20.09|University of Washington|EMNLP2020(findings)|[RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models](https://arxiv.org/abs/2009.11462)|
|21.09|University of Oxford|ACL2022|[TruthfulQA: Measuring How Models Mimic Human Falsehoods](https://arxiv.org/abs/2109.07958)|
|22.03|MIT|ACL2022|[ToxiGen: A Large-Scale Machine-Generated datasets for Adversarial and Implicit Hate Speech Detection](https://arxiv.org/abs/2203.09509)|


### 📖教程, 文章, 演示, 演讲

|日期|分类|标题|链接地址|
|:-:|:-:|:-:|:-:|
|23.10|教程|Awesome-LLM-Safety|[链接](https://github.com/ydyjya/Awesome-LLM-Safety)|

### 📚资源📚
- Toxicity - [RealToxicityPrompts datasets](https://toxicdegeneration.allenai.org/)
- Truthfulness - [TruthfulQA datasets](https://github.com/sylinrl/TruthfulQA)

### 其他
👉[Latest&Comprehensive datasets & Benchmark Paper](./subtopic/Datasets&Benchmark.md)


---
## 🧑‍🎓作者信息


**🤗如果你有任何疑问欢迎咨询作者!🤗**

✉️: [ydyjya](https://github.com/ydyjya) ➡️ zhouzhenhong@bupt.edu.cn

💬: **交流LLM Safety**

<div align="center">

<div align="center">

[Wechat Group](./resource/wechat.png) | [My Wechat](./resource/wechat.png)

</div>

</div>

---

[![Star History Chart](https://api.star-history.com/svg?repos=ydyjya/Awesome-LLM-Safety&type=Date)](https://star-history.com/#ydyjya/Awesome-LLM-Safety&Date)

**[⬆ 回到顶部](#table-of-contents)**