# ICML 2024

<!-- In ICML 2024, there are total xxx papers, and as for safety, there are xxx papars.  -->

## ðŸ“‘Papers-Oral (7 papers)

| Date  |                          Institute                           |     Publication     |                            Paper                             |                           Keywords                           |
| :---: | :----------------------------------------------------------: | :-----------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 24.02 |                  Princeton University, Anthropic, Google DeepMind                   |      ICML2024      | [How do Large Language Models Navigate Conflicts between Honesty and Helpfulness?](https://openreview.net/forum?id=685vj0lC9z) | **Honesty and Helpfulness**&**Alignment**&**Prompts** |
| 24.04 |                  Tsinghua University, OpenPsi Inc, Shanghai Qi Zhi Institute                   |      ICML2024      | [Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study](https://openreview.net/forum?id=6XH8R7YrSk) | **Alignment**&**DPO** |
| 23.11 |                  Google DeepMind                   |      ICML2024      | [Scalable AI Safety via Doubly-Efficient Debate](https://openreview.net/forum?id=6jmdOTRMIO) | **Evaluation**&**Protocols** |
| 24.02 |                  Huazhong University of Science and Technology                   |      ICML2024      | [MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark](https://openreview.net/forum?id=dbFEFHAD79) | **LLM-as-a-Judge**&**Multimodel** |
| 23.12 |                  Redwood Research, Anthropic                   |      ICML2024      | [AI Control: Improving Safety Despite Intentional Subversion](https://openreview.net/forum?id=KviM5k8pcP) | **Red Team**&**Protocols** |
| 24.01 |                  University of Michigan                   |      ICML2024      | [A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity](https://openreview.net/forum?id=dBqHGZPGZI) | **Alignment**&**Explaination** |
| 24.02 |                  UC Berkeley, Meta AI, TU Dresden                   |      ICML2024      | [A Touch, Vision, and Language Dataset for Multimodal Alignment](https://openreview.net/forum?id=tFEOOH9eH0) | **Alignment**&**Multimodal** |