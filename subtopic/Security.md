# Security


## ðŸ“‘PapersðŸ“‘

- 20.10 - arxiv - [Recipes for Safety in Open-domain Chatbots](https://arxiv.org/abs/2010.07079)
  - **Toxic Behavior**&**Open-domain**
- 23.07 - arxiv - [Jailbroken: How Does LLM Safety Training Fail?](https://arxiv.org/abs/2307.02483)
  - **Jailbreak**&**Competing Objectives**&**Mismatched Generalization**
- 23.07 - arxiv  - [Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)
  - **Jailbreak**&**Transferable Attack**&**Adversarial Attack**

## ðŸ’»Presentations & TalksðŸ’»


## ðŸ“–Tutorials & WorkshopsðŸ“–

- 23.10 - GitHub - [awesome-LLM-safety-paper-list](https://github.com/ydyjya/awesome-LLM-safety-paper-list)
  - **Repo**&**Tutorials**

## ðŸ“°News & ArticlesðŸ“°
