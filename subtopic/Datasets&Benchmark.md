# Datasets & Benchmark


## ðŸ“‘Papers

| Date  |                     Institute                      |       Publication       |                                                                  Paper                                                                   |                               Keywords                                |
|:-----:|:--------------------------------------------------:|:-----------------------:|:----------------------------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------:|
| 20.09 |              University of Washington              |   EMNLP2020(findings)   |             [RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models](https://arxiv.org/abs/2009.11462)             |                             **Toxicity**                              |
| 21.09 |                University of Oxford                |         ACL2022         |                       [TruthfulQA: Measuring How Models Mimic Human Falsehoods](https://arxiv.org/abs/2109.07958)                        |                           **Truthfulness**                            |
| 22.03 |                        MIT                         |         ACL2022         | [ToxiGen: A Large-Scale Machine-Generated datasets for Adversarial and Implicit Hate Speech Detection](https://arxiv.org/abs/2203.09509) |                             **Toxicity**                              |
| 23.11 |                  Fudan University                  |          arxiv          |                     [JADE: A Linguistic-based Safety Evaluation Platform for LLM](https://arxiv.org/abs/2311.00286)                      |                         **Safety Benchmarks**                         |
| 23.11 |                  UNC-Chapel Hill                   |          arxiv          |        [Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges](https://arxiv.org/abs/2311.03287)         |            **Hallucination**&**Benchmark**&**Multimodal**             |
| 23.11 |                  IBM Research AI                   | EMNLP2023(GEM workshop) |                      [Unveiling Safety Vulnerabilities of Large Language Models](https://arxiv.org/abs/2311.04124)                       | **Adversarial Examples**&**Clustering**&**Automatically Identifying** |
| 23.11 | The Hong Kong University of Science and Technology |          arxiv          |               [P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models](https://arxiv.org/abs/2311.04044)                |            **Differential Privacy**&**Privacy Evaluation**            |




## ðŸ“šResource

- Toxicity - [RealToxicityPrompts datasets](https://toxicdegeneration.allenai.org/)
- Truthfulness - [TruthfulQA datasets](https://github.com/sylinrl/TruthfulQA)