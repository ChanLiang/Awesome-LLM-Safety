# Datasets & Benchmark


## ðŸ“‘Papers

| Date  |                                Institute                                 |       Publication       |                                                                  Paper                                                                   |                               Keywords                                |
|:-----:|:------------------------------------------------------------------------:|:-----------------------:|:----------------------------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------:|
| 20.09 |                         University of Washington                         |   EMNLP2020(findings)   |             [RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models](https://arxiv.org/abs/2009.11462)             |                             **Toxicity**                              |
| 21.09 |                           University of Oxford                           |         ACL2022         |                       [TruthfulQA: Measuring How Models Mimic Human Falsehoods](https://arxiv.org/abs/2109.07958)                        |                           **Truthfulness**                            |
| 22.03 |                                   MIT                                    |         ACL2022         | [ToxiGen: A Large-Scale Machine-Generated datasets for Adversarial and Implicit Hate Speech Detection](https://arxiv.org/abs/2203.09509) |                             **Toxicity**                              |
| 23.11 |                             Fudan University                             |          arxiv          |                     [JADE: A Linguistic-based Safety Evaluation Platform for LLM](https://arxiv.org/abs/2311.00286)                      |                         **Safety Benchmarks**                         |
| 23.11 |                             UNC-Chapel Hill                              |          arxiv          |        [Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges](https://arxiv.org/abs/2311.03287)         |            **Hallucination**&**Benchmark**&**Multimodal**             |
| 23.11 |                             IBM Research AI                              | EMNLP2023(GEM workshop) |                      [Unveiling Safety Vulnerabilities of Large Language Models](https://arxiv.org/abs/2311.04124)                       | **Adversarial Examples**&**Clustering**&**Automatically Identifying** |
| 23.11 |            The Hong Kong University of Science and Technology            |          arxiv          |               [P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models](https://arxiv.org/abs/2311.04044)                |            **Differential Privacy**&**Privacy Evaluation**            |
| 23.11 |                               UC Berkeley                                |          arxiv          |                                     [CAN LLMS FOLLOW SIMPLE RULES](https://arxiv.org/abs/2311.04235)                                     |                 **Evaluation**&**Attack Strategies**                  |
| 23.11 |                      University of Central Florida                       |          arxiv          |                   [THOS: A Benchmark Dataset for Targeted Hate and Offensive Speech](https://arxiv.org/abs/2311.06446)                   |           **Hate Speech**&**Offensive Speech**&**Dataset**            |
| 23.11 | Beijing Jiaotong University; DAMO Academy, Alibaba Group, Peng Cheng Lab |          arXiv          |          [AMBER: An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination Evaluation](https://arxiv.org/abs/2311.07397)           |       Multi-modal Large Language Models&Hallucination&Benchmark       |




## ðŸ“šResource

- Toxicity - [RealToxicityPrompts datasets](https://toxicdegeneration.allenai.org/)
- Truthfulness - [TruthfulQA datasets](https://github.com/sylinrl/TruthfulQA)