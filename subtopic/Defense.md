# Defense

## Different from the main READMEüïµÔ∏è

- Within this subtopic, we will be updating with the latest articles. This will help researchers in this area to quickly understand recent trends.
- In addition to providing the most recent updates, we will also add keywords to each subtopic to help you find content of interest more quickly.
- Within each subtopic, we will also update with profiles of scholars we admire and endorse in the field. Their work is often of high quality and forward-looking!"


## üìëPapers

| Date  |                                                       Institute                                                        | Publication |                                                                Paper                                                                |                                Keywords                                 |
|:-----:|:----------------------------------------------------------------------------------------------------------------------:|:-----------:|:-----------------------------------------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------:|
| 21.07 |                                                    Google Research                                                     |   ACL2022   |               [Deduplicating Training Data Makes Language Models Better](https://aclanthology.org/2022.acl-long.577/)               |        **Privacy Protected**&**Deduplication**&**Memorization**         |
| 23.09 |                                                 University of Maryland                                                 |    arxiv    |                       [Certifying LLM Safety against Adversarial Prompting](https://arxiv.org/abs/2309.02705)                       |                **Safety Filter**&**Adversarial Prompts**                |
| 23.09 |                                                 University of Maryland                                                 |    arxiv    |            [BASELINE DEFENSES FOR ADVERSARIAL ATTACKS AGAINST ALIGNED LANGUAGE MODELS](https://arxiv.org/abs/2309.00614)            |     **Perplexity**&**Input Preprocessing**&**Adversarial Training**     |
| 23.10 |                                               University of Pennsylvania                                               |    arxiv    |             [SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks](https://arxiv.org/abs/2310.03684)             |          **Jailbreak**&**Adversarial Attack**&**Perturbation**          |
| 23.11 |                                            University of California Irvine                                             |    arxiv    |          [Robust Safety Classifier for Large Language Models: Adversarial Prompt Shield](https://arxiv.org/abs/2311.00172)          |           **Adversarial Prompt Shield**&**Safety Classifier**           |
| 23.11 |                                            Child Health Evaluative Sciences                                            |    arxiv    |              [Pyclipse, a library for deidentification of free-text clinical notes](https://arxiv.org/abs/2311.02748)               |               **Clinical Text Data**&**Deidentification**               |
| 23.11 | University of Southern California, Harvard University, University of California Davis, University of Wisconsin-Madison |    arxiv    | [Test-time Backdoor Mitigation for Black-Box Large Language Models with Defensive Demonstrations](https://arxiv.org/abs/2311.09763) | **Backdoor Attacks**&**Defensive Demonstrations**&**Test-Time Defense** |



## üíªPresentations & Talks


## üìñTutorials & Workshops

| Date  |   Type    |       Title        |                         URL                          |
|:-----:|:---------:|:------------------:|:----------------------------------------------------:|
| 23.10 | Tutorials | Awesome-LLM-Safety | [link](https://github.com/ydyjya/Awesome-LLM-Safety) |

## üì∞News & Articles

## üßë‚Äçüè´Scholars
