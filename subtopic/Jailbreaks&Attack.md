# Jailbreaks&Attack

## Different from the main READMEüïµÔ∏è

- Within this subtopic, we will be updating with the latest articles. This will help researchers in this area to quickly understand recent trends.
- In addition to providing the most recent updates, we will also add keywords to each subtopic to help you find content of interest more quickly.
- Within each subtopic, we will also update with profiles of scholars we admire and endorse in the field. Their work is often of high quality and forward-looking!"

## üìëPapers

| Date  |            Institute             |         Publication          |                                                                         Paper                                                                         |                                        Keywords                                         |
|:-----:|:--------------------------------:|:----------------------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------------------:|
| 22.11 |            AE Studio             | NIPS2022(ML Safety Workshop) |                           [Ignore Previous Prompt: Attack Techniques For Language Models](https://arxiv.org/abs/2211.09527)                           |                           **Prompt Injection**&**Misaligned**                           |
| 23.02 |       Saarland University        |            arxiv             | [Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection](https://arxiv.org/abs/2302.12173) | **Adversarial Prompting**&**Indirect Prompt Injection**&**LLM-Integrated Applications** |
| 23.06 |              Google              |            arxiv             |                                [Are aligned neural networks adversarially aligned?](https://arxiv.org/abs/2306.15447)                                 |                              **Multimodal**&**Jailbreak**                               |
| 23.07 |               CMU                |            arxiv             |                     [Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)                     |              **Jailbreak**&**Transferable Attack**&**Adversarial Attack**               |
| 23.07 | Nanyang Technological University |           NDSS2023           |                   [MasterKey: Automated Jailbreak Across Multiple Large Language Model Chatbots](https://arxiv.org/abs/2307.08715)                    |             **Jailbreak**&**Reverse-Engineering**&**Automatic Generation**              |
| 23.11 |              MBZUAI              |            arxiv             |                [Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks](https://arxiv.org/abs/2311.00508)                |        **Adversarially-synthesized Texts**&**Word-level Attacks**&**Evaluation**        |
| 23.11 |        Palisade Research         |            arxiv             |                        [BadLlama: cheaply removing safety fine-tuning from Llama 2-Chat 13B](https://arxiv.org/abs/2311.00117)                        |                              **Remove Safety Fine-tuning**                              |
| 23.11 |       University of Twente       |         ICNLSP 2023          |                         [Efficient Black-Box Adversarial Attacks on Neural Text Detectors](https://arxiv.org/abs/2311.01873)                          |                      **Misclassification**&**Adversarial attacks**                      |


## üíªPresentations & Talks


## üìñTutorials & Workshops

| Date  |   Type    |       Title        |                         URL                          |
|:-----:|:---------:|:------------------:|:----------------------------------------------------:|
| 23.10 | Tutorials | Awesome-LLM-Safety | [link](https://github.com/ydyjya/Awesome-LLM-Safety) |

## üì∞News & Articles

## üßë‚Äçüè´Scholars