# Robustness

## Different from the main READMEüïµÔ∏è

- Within this subtopic, we will be updating with the latest articles. This will help researchers in this area to quickly understand recent trends.
- In addition to providing the most recent updates, we will also add keywords to each subtopic to help you find content of interest more quickly.
- Within each subtopic, we will also update with profiles of scholars we admire and endorse in the field. Their work is often of high quality and forward-looking!"

## üìëPapers

| Date  |                               Institute                               |                                     Publication                                     |                                                                             Paper                                                                             |                                      Keywords                                      |
|:-----:|:---------------------------------------------------------------------:|:-----------------------------------------------------------------------------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------:|
| 23.02 |                          Microsoft Research                           | ICLR 2023(workshop on Trustworthy and Reliable Large-Scale Machine Learning Models) |                     [On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective](https://arxiv.org/abs/2302.12095)                      | **Robustness Evaluation**&**Adversarial Robustness**&**Out-of-Distribution (OOD)** |
| 23.06 |              University of Illinois at Urbana-Champaign               |                                        arxiv                                        |                        [DECODINGTRUST: A Comprehensive Assessment of Trustworthiness in GPT Models](https://arxiv.org/abs/2306.11698)                         |                 **Robustness**&**Ethics**&**Privacy**&**Toxicity**                 |
| 23.08 | CISPA Helmholtz Center for Information Security & Tsinghua University |                                        arxiv                                        | [Robustness Over Time: Understanding Adversarial Examples‚Äô Effectiveness on Longitudinal Versions of Large Language Models](https://arxiv.org/abs/2308.07847) |                  **Longitudinal Study**&**Robustness Assessment**                  |
| 23.11 |                                  CMU                                  |                          AACL2023(ART or Safety workshop)                           |                                              [Measuring Adversarial Datasets](https://arxiv.org/abs/2311.03566)                                               |         **Adversarial Robustness**&**AI Safety**&**Adversarial Datasets**          |
| 23.11 |                          Amazon Alexa AI-NU                           |                                        arXiv                                        |                                 [JAB: Joint Adversarial Prompting and Belief Augmentation](https://arxiv.org/abs/2311.09473)                                  |          **Adversarial Prompting**&T**oxicity Reduction**&**Robustness**           |
| 24.01 | University of Trento, Concordia University, Mila-Quebec AI Institute  |                                        arxiv                                        |                                           [Are LLMs Robust for Spoken Dialogues?](https://arxiv.org/abs/2401.02297)                                           |  **Task-Oriented Dialogues**&**Automatic Speech Recognition**&**Error Analysis**   |



## üíªPresentations & Talks


## üìñTutorials & Workshops

| Date  |   Type    |       Title        |                         URL                          |
|:-----:|:---------:|:------------------:|:----------------------------------------------------:|
| 23.10 | Tutorials | Awesome-LLM-Safety | [link](https://github.com/ydyjya/Awesome-LLM-Safety) |

## üì∞News & Articles

## üßë‚Äçüè´Scholars